{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShedovaNastya/Face-Recognition-Project/blob/main/Test_of_ML_algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тест классических алгоритмов машиннного обучения"
      ],
      "metadata": {
        "id": "X6qm4DC_nM_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LHYFw4xGVzFT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import list_models, get_model\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU-Dglc5Wb7S",
        "outputId": "7803174b-e2de-46c6-bc60-151928e1373b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Kly0lfGWgYo"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/celebA_train_500.zip\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FohoDvwWwas"
      },
      "source": [
        "#Датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMjalFi1Whg9"
      },
      "outputs": [],
      "source": [
        "class FaceDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, images_folder, label_folder, sample_folder, type_dataset, transform):\n",
        "      \"\"\"\n",
        "      image_folder: путь до папки с изображениями\n",
        "      label_folder: путь до файла, где какой человек находится\n",
        "      sample_folder: путь до файла к какому датасету относится конкретное изображение\n",
        "      type_dataset: датасет, который нас сейчас интересует\n",
        "      transform: преобразование изображения\n",
        "      \"\"\"\n",
        "      self.images_folder = images_folder\n",
        "      self.label_folder = label_folder\n",
        "      self.sample_folder = sample_folder\n",
        "      self.type_dataset = type_dataset\n",
        "      self.transform = transform\n",
        "\n",
        "\n",
        "      with open(self.label_folder, 'r') as file: #человек\n",
        "        self.labels = {}\n",
        "        for i in file.readlines():\n",
        "          key, value = i.split()\n",
        "          self.labels[key] = int(value)\n",
        "\n",
        "      with open(self.sample_folder, 'r') as file: #классификация датасетов\n",
        "        self.samples = {}\n",
        "        for i in file.readlines():\n",
        "          key, value = i.split()\n",
        "          self.samples[key] = int(value)\n",
        "\n",
        "      self.files = [i for i in os.listdir(self.images_folder) if self.samples.get(i, 5) == self.type_dataset]\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      image_name = self.images_folder + self.files[idx]\n",
        "      image = np.array(Image.open(image_name))\n",
        "      image = Image.fromarray(image[77:-41,45:-50])\n",
        "      label = int(self.labels[self.files[idx]])\n",
        "      image = self.transform(image)\n",
        "      return image, label\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQJlJQUbWpD4"
      },
      "outputs": [],
      "source": [
        "train_dataset = FaceDataset('/content/celebA_train_500/celebA_imgs/',\n",
        "                            '/content/celebA_train_500/celebA_anno.txt',\n",
        "                            '/content/celebA_train_500/celebA_train_split.txt',\n",
        "                            0,\n",
        "                            T.Compose([\n",
        "                                T.Resize((224, 224)), T.ToTensor()\n",
        "                            ]))\n",
        "val_dataset = FaceDataset('/content/celebA_train_500/celebA_imgs/',\n",
        "                            '/content/celebA_train_500/celebA_anno.txt',\n",
        "                            '/content/celebA_train_500/celebA_train_split.txt',\n",
        "                            1,\n",
        "                            T.Compose([\n",
        "                                T.Resize((224, 224)), T.ToTensor()\n",
        "                            ]))\n",
        "test_dataset = FaceDataset('/content/celebA_train_500/celebA_imgs/',\n",
        "                            '/content/celebA_train_500/celebA_anno.txt',\n",
        "                            '/content/celebA_train_500/celebA_train_split.txt',\n",
        "                            2,\n",
        "                            T.Compose([\n",
        "                                T.Resize((224, 224)), T.ToTensor()\n",
        "                            ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqGqUkwTZhSS"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size = 30, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 30, shuffle = False)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 30, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIPJhY1wX6ZC"
      },
      "source": [
        "# Модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmFeyhbAXOMp",
        "outputId": "8153a8fe-ddfa-4918-c78c-f366296e9b67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 41.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Модель для оценки\n",
        "m1 = get_model(\"efficientnet_b0\", weights=\"IMAGENET1K_V1\")\n",
        "m1.classifier[1] = torch.nn.Linear(in_features=1280, out_features=500, bias=True)\n",
        "device = 'cpu'\n",
        "m1 = m1.to(device)\n",
        "\n",
        "\n",
        "filename = '/content/drive/MyDrive/eff_net_param_m1.pth'\n",
        "m1.load_state_dict(torch.load(filename, map_location=device))\n",
        "\n",
        "m1.classifier = m1.classifier[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdHWlNluYO6b"
      },
      "outputs": [],
      "source": [
        "def compute_embeddings(model, loader):#функция считает выход ембеддингового слоя\n",
        "  '''\n",
        "  compute embeddings from the trained model for list of images.\n",
        "  params:\n",
        "    model: trained nn model that takes images and outputs embeddings\n",
        "    images_list: list of images paths to compute embeddings for\n",
        "  output:\n",
        "    list: list of model embeddings. Each embedding corresponds to images\n",
        "          names from images_list\n",
        "  '''\n",
        "  out_data = []\n",
        "  out_labels = []\n",
        "  device = \"cuda:0\"\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data, labels in tqdm(loader):\n",
        "      data = data.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      out_data.append(model(data))\n",
        "      out_labels.append(labels)\n",
        "  return torch.cat(out_data), torch.cat(out_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vd4gqSI6OKki"
      },
      "outputs": [],
      "source": [
        "train_em, train_lab = compute_embeddings(m1, train_loader)\n",
        "val_em, val_lab = compute_embeddings(m1, val_loader)\n",
        "test_em, test_lab = compute_embeddings(m1, test_loader)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "embeddings_m1 = {\"train\":{\n",
        "    \"data\": train_em.cpu().numpy(),\n",
        "    \"label\": train_lab.cpu().numpy()\n",
        "},\n",
        " \"val\": {\n",
        "     \"data\": val_em.cpu().numpy(),\n",
        "     \"label\": val_lab.cpu().numpy()\n",
        " },\n",
        " \"test\": {\n",
        "     \"data\": test_em.cpu().numpy(),\n",
        "     \"label\": test_lab.cpu().numpy()\n",
        " }}\n",
        "\n",
        "import pickle\n",
        "with open('embeddings_m1.pkl', 'wb') as file:\n",
        "\n",
        "    # A new file will be created\n",
        "    pickle.dump(embeddings_m1, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx-ceuEOMu0c",
        "outputId": "e538f44c-50ce-4222-a40b-d90d1641161d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'data': array([[-0.1953766 ,  2.7521744 ,  0.09171401, ...,  0.27497578,\n",
              "           0.23698662,  0.04447447],\n",
              "         [ 0.2088342 , -0.0933115 ,  2.2184422 , ...,  0.01036019,\n",
              "          -0.11764833, -0.0998802 ],\n",
              "         [-0.11963991,  1.1833105 , -0.05651244, ...,  0.11861803,\n",
              "           2.501749  ,  0.09346844],\n",
              "         ...,\n",
              "         [ 0.38081095,  0.3446979 ,  0.60753024, ...,  0.0797212 ,\n",
              "          -0.04109422, -0.08527862],\n",
              "         [-0.0832733 ,  0.53367627,  0.724545  , ...,  0.01339865,\n",
              "           0.04168406,  0.15918595],\n",
              "         [ 0.26264298,  4.1949553 , -0.14428589, ...,  3.961145  ,\n",
              "           0.21232411,  0.35450253]], dtype=float32),\n",
              "  'label': array([ 22, 367, 309, ..., 313, 450, 339])},\n",
              " 'val': {'data': array([[-0.12083704,  0.9092367 ,  0.03618243, ..., -0.12314168,\n",
              "          -0.09892447, -0.15674733],\n",
              "         [ 0.02604393,  0.660122  ,  0.00466253, ...,  0.15259533,\n",
              "          -0.11874288,  0.6394765 ],\n",
              "         [-0.17250489,  1.1275271 ,  1.4078394 , ..., -0.15333782,\n",
              "          -0.10927305,  0.17079279],\n",
              "         ...,\n",
              "         [-0.12610947,  0.8360259 ,  0.04921529, ...,  0.57845175,\n",
              "           0.37086645, -0.09057771],\n",
              "         [-0.07023334,  0.12115476,  0.27406812, ...,  0.5712807 ,\n",
              "          -0.13873285, -0.12716003],\n",
              "         [-0.08925069,  0.5625458 , -0.08441017, ...,  1.8757533 ,\n",
              "           0.68297267,  0.9405329 ]], dtype=float32),\n",
              "  'label': array([353, 238, 346, ..., 324, 273, 475])},\n",
              " 'test': {'data': array([[ 0.2481066 ,  0.6006195 ,  1.916649  , ..., -0.19640382,\n",
              "          -0.04026499,  0.03313852],\n",
              "         [-0.15271638,  0.5704885 ,  0.39250407, ..., -0.04177492,\n",
              "           0.61881536,  0.23932755],\n",
              "         [-0.14258   ,  1.3242785 , -0.03289833, ...,  0.6933529 ,\n",
              "           1.0534658 ,  0.74258256],\n",
              "         ...,\n",
              "         [-0.14449272, -0.06159414, -0.09136111, ..., -0.11278974,\n",
              "          -0.0751339 , -0.09339447],\n",
              "         [-0.03188317,  0.0082491 ,  0.12757762, ...,  3.606301  ,\n",
              "           0.01598377,  1.7522768 ],\n",
              "         [-0.13697162,  1.049395  ,  0.1662597 , ...,  0.09796869,\n",
              "           0.5211339 ,  0.1394298 ]], dtype=float32),\n",
              "  'label': array([302, 247, 110, ...,  90, 345, 420])}}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/embeddings_m1.pkl', 'rb') as file:\n",
        "    # Десериализуем данные из файла\n",
        "     embeddings_m1= pickle.load(file)\n",
        "embeddings_m1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVNcs6vinNoQ"
      },
      "source": [
        "# KNeighborsClassifier 0,7412"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlcnHEd4mfRA"
      },
      "source": [
        "Classifier implementing the k-nearest neighbors vote.\n",
        "Parameters:\n",
        "\n",
        "**1. n_neighborsint**, default=5\n",
        "Number of neighbors to use by default for kneighbors queries.\n",
        "\n",
        "\n",
        "\n",
        "**2. weights**{‘uniform’, ‘distance’}, callable or None, default=’uniform’\n",
        "Weight function used in prediction. Possible values:\n",
        "\n",
        "‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
        "\n",
        "‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
        "\n",
        "[callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
        "\n",
        "Refer to the example entitled Nearest Neighbors Classification showing the impact of the weights parameter on the decision boundary.\n",
        "\n",
        "\n",
        "\n",
        "**3. algorithm**{‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, default=’auto’\n",
        "Algorithm used to compute the nearest neighbors:\n",
        "\n",
        "‘ball_tree’ will use BallTree\n",
        "\n",
        "‘kd_tree’ will use KDTree\n",
        "\n",
        "‘brute’ will use a brute-force search.\n",
        "\n",
        "‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.\n",
        "\n",
        "Note: fitting on sparse input will override the setting of this parameter, using brute force.\n",
        "\n",
        "\n",
        "\n",
        "**4. leaf_sizeint**, default=30\n",
        "Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75OtHDxVlU3c",
        "outputId": "71eef30a-2157-4bf8-e6d3-b749c93a6524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.715122470713525\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors = 3)\n",
        "\n",
        "model.fit(embeddings_m1['train']['data'], embeddings_m1['train']['label'])\n",
        "predictions = model.predict(embeddings_m1['val']['data'])\n",
        "print(accuracy_score(embeddings_m1['val']['label'], predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3vLBYb_o6GX",
        "outputId": "c112bde4-54d6-4284-f82e-a4f68f7dd97d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 distance auto 25 0.7369542066027689\n",
            "7 distance auto 25 0.7401490947816827\n",
            "9 distance auto 25 0.7412140575079872\n"
          ]
        }
      ],
      "source": [
        "acc = 0.72\n",
        "n_neigh = [3,7,9,12,15,20]\n",
        "weights = ['uniform', 'distance']\n",
        "algorithms = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "leaf_size= [25,30,35,40]\n",
        "for neighbors in n_neigh:\n",
        "  for weight in weights:\n",
        "      for algo in algorithms:\n",
        "        for size in leaf_size:\n",
        "            model = KNeighborsClassifier(n_neighbors = neighbors, weights = weight, algorithm = algo, leaf_size = size)\n",
        "            model.fit(embeddings_m1['train']['data'], embeddings_m1['train']['label'])\n",
        "            predictions = model.predict(embeddings_m1['val']['data'])\n",
        "            accuracy = accuracy_score(embeddings_m1['val']['label'], predictions)\n",
        "            if accuracy > acc:\n",
        "              acc = accuracy\n",
        "              print(neighbors, weight, algo, size, accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYx-s2lXrf3q"
      },
      "source": [
        "#Linear Support Vector Classification 0,7966 THE BEST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjhFS5qRxT_h"
      },
      "source": [
        "Linear Support Vector Classification.\n",
        "\n",
        "Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
        "\n",
        "The main differences between LinearSVC and SVC lie in the loss function used by default, and in the handling of intercept regularization between those two implementations.\n",
        "\n",
        "This class supports both dense and sparse input and the multiclass support is handled according to a one-vs-the-rest scheme.\n",
        "\n",
        "Read more in the User Guide.\n",
        "\n",
        "Parameters:\n",
        "1. penalty{‘l1’, ‘l2’}, default=’l2’\n",
        "Specifies the norm used in the penalization. The ‘l2’ penalty is the standard used in SVC. The ‘l1’ leads to coef_ vectors that are sparse.\n",
        "\n",
        "2. loss{‘hinge’, ‘squared_hinge’}, default=’squared_hinge’\n",
        "Specifies the loss function. ‘hinge’ is the standard SVM loss (used e.g. by the SVC class) while ‘squared_hinge’ is the square of the hinge loss. The combination of penalty='l1' and loss='hinge' is not supported.\n",
        "\n",
        "3. dual“auto” or bool, default=”auto”\n",
        "Select the algorithm to either solve the dual or primal optimization problem. Prefer dual=False when n_samples > n_features. dual=\"auto\" will choose the value of the parameter automatically, based on the values of n_samples, n_features, loss, multi_class and penalty. If n_samples < n_features and optimizer supports chosen loss, multi_class and penalty, then dual will be set to True, otherwise it will be set to False.\n",
        "\n",
        "4. tol float, default=1e-4\n",
        "Tolerance for stopping criteria.\n",
        "\n",
        "5. Cfloat, default=1.0\n",
        "Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. For an intuitive visualization of the effects of scaling the regularization parameter C, see Scaling the regularization parameter for SVCs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = LinearSVC(penalty='l2', loss='squared_hinge')\n",
        "\n",
        "model.fit(embeddings_m1['train']['data'], embeddings_m1['train']['label'])\n",
        "predictions = model.predict(embeddings_m1['val']['data'])\n",
        "print(accuracy_score(embeddings_m1['val']['label'], predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9siWrfSYbqoF",
        "outputId": "d89a2505-c658-454c-bfc9-3e1d64c2901e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7955271565495208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A1xNWx-AtOwf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533a2724-7e69-41b5-d0e0-b067e31c3991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0001 ovr 0.7955271565495208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0001 crammer_singer 0.7965921192758253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from  sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc = 0\n",
        "tols = [0.0001, 0.001]\n",
        "multi_classes = ['ovr', 'crammer_singer']\n",
        "for t in tols:\n",
        "  for mc in multi_classes:\n",
        "        model = LinearSVC(tol = t, multi_class = mc)\n",
        "        # Обучение модели\n",
        "        model.fit(embeddings_m1['train']['data'], embeddings_m1['train']['label'])\n",
        "\n",
        "        # Получение предсказаний\n",
        "        predictions = model.predict(embeddings_m1['val']['data'])\n",
        "        accuracy = accuracy_score(embeddings_m1['val']['label'], predictions)\n",
        "        if acc< accuracy:\n",
        "          acc = accuracy\n",
        "          print(t,mc, accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BernoulliNB 0.76"
      ],
      "metadata": {
        "id": "9U_P_mfjmpun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = BernoulliNB(alpha=1.0, force_alpha=True)\n",
        "\n",
        "model.fit(embeddings_m1['train']['data'], embeddings_m1['train']['label'])\n",
        "predictions = model.predict(embeddings_m1['val']['data'])\n",
        "print(accuracy_score(embeddings_m1['val']['label'], predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ3_v88tmo2B",
        "outputId": "a7dd7c79-0583-4cce-807e-f9661416d877"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7646432374866879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GaussianNB 0,*7*"
      ],
      "metadata": {
        "id": "fcuzCkcPoIjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = GaussianNB(priors=None, var_smoothing=1e-09)\n",
        "\n",
        "model.fit(embeddings_m1['train']['data'], embeddings_m1['train']['label'])\n",
        "predictions = model.predict(embeddings_m1['val']['data'])\n",
        "print(accuracy_score(embeddings_m1['val']['label'], predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAFnmox2oFSD",
        "outputId": "2fc34a49-0ef1-4119-eb6f-8a015df49993"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6996805111821086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lneqXo_SXA1L"
      },
      "source": [
        "# RandomForestClassifier 0.67"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKhc1Hg3Q9IW",
        "outputId": "1f16fc44-7cb2-480f-e278-39342aac330f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6741214057507987\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "model.fit(embeddings_m1['train']['data'], embeddings_m1['train']['label'])\n",
        "predictions = model.predict(embeddings_m1['val']['data'])\n",
        "print(accuracy_score(embeddings_m1['val']['label'], predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEST"
      ],
      "metadata": {
        "id": "d9zedFodrA0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лучше всего себя показала модель Linear Support Vector Classification ~0.8. Посмотрим ее результат на тестовой выборке"
      ],
      "metadata": {
        "id": "2EMEWH4xrJl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from  sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = LinearSVC(tol = 0.001, multi_class = 'crammer_singer')\n",
        "\n",
        "model.fit(embeddings_m1['train']['data'], embeddings_m1['train']['label'])\n",
        "predictions = model.predict(embeddings_m1['test']['data'])\n",
        "print(accuracy_score(embeddings_m1['test']['label'], predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EDjBxaBrALk",
        "outputId": "706ece65-c397-4bb1-d315-2bf5ffb2f2e5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7872876022655758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT = 0.7872"
      ],
      "metadata": {
        "id": "eKE0-mvcsr_q"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOjNktzkSGYpmwqwkaXiVnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}